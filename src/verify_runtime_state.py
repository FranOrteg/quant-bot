# src/verify_runtime_state.py
import os
import re
import json
import math
import pandas as pd
import numpy as np
from datetime import datetime
from pathlib import Path

# 1) Importar el selector real del proyecto
from src.strategy_selector import select_best_strategy

DATA_PATH = Path("data/BTCUSDC_15m.csv")
LOG_PATH  = Path("logs/live_trader.log")
OPT_PATH  = Path("results/rsi_optimization_15m.csv")

def _safe_float(x):
    try:
        return float(x)
    except Exception:
        return np.nan

def load_and_validate_csv(path: Path) -> pd.DataFrame:
    if not path.exists():
        raise FileNotFoundError(f"No existe {path}. Aseg√∫rate de que el bot est√© gener√°ndolo.")

    # Cargar crudo (sin parseo todav√≠a) para detectar contaminaciones
    raw = path.read_text(encoding="utf-8", errors="ignore")
    lines = raw.splitlines()

    bad_lines = []
    clean_lines = []
    header_seen = False
    for i, ln in enumerate(lines):
        if not header_seen:
            clean_lines.append(ln)
            header_seen = True
            continue

        # Heur√≠stica: una l√≠nea v√°lida debe tener 6 columnas separadas por coma
        # y las columnas 2..6 deben ser num√©ricas (open,high,low,close,volume)
        parts = ln.split(",")
        if len(parts) != 6:
            bad_lines.append((i+1, "num_cols", ln))
            continue

        ts, o, h, l, c, v = parts
        # Si el volumen tiene texto del log pegado, no ser√° num√©rico
        if any((_safe_float(x) is np.nan) for x in (o, h, l, c, v)):
            bad_lines.append((i+1, "non_numeric", ln))
            continue

        clean_lines.append(ln)

    # Reporte de l√≠neas malas
    if bad_lines:
        print("‚ö†Ô∏è Se detectaron l√≠neas corruptas en el CSV (se ignorar√°n en la validaci√≥n):")
        for n, reason, ln in bad_lines[:5]:
            print(f"   ‚Ä¢ L√≠nea {n} [{reason}]: {ln[:120]}{'...' if len(ln)>120 else ''}")
        if len(bad_lines) > 5:
            print(f"   ‚Ä¢ y {len(bad_lines)-5} m√°s...")

    # Reconstruir CSV solo con l√≠neas v√°lidas para la validaci√≥n en memoria
    tmp = "\n".join(clean_lines)
    from io import StringIO
    df = pd.read_csv(StringIO(tmp))

    # Parseo de timestamp
    df["timestamp"] = pd.to_datetime(df["timestamp"], utc=True, errors="coerce")
    # Coherencia temporal
    df = df.dropna(subset=["timestamp"]).sort_values("timestamp").reset_index(drop=True)

    # Eliminar duplicados de timestamp (dejar el √∫ltimo)
    before = len(df)
    df = df.drop_duplicates(subset=["timestamp"], keep="last")
    after = len(df)
    if after < before:
        print(f"‚ÑπÔ∏è Eliminados {before-after} duplicados de timestamp (en validaci√≥n).")

    # Asegurar tipos num√©ricos
    for col in ["open", "high", "low", "close", "volume"]:
        df[col] = pd.to_numeric(df[col], errors="coerce")
    df = df.dropna(subset=["open", "high", "low", "close", "volume"]).reset_index(drop=True)

    return df

def compute_indicators_and_signal(df: pd.DataFrame, rsi_period: int, sma_period: int,
                                  rsi_buy: int, rsi_sell: int) -> pd.DataFrame:
    # SMA
    df["sma"] = df["close"].rolling(sma_period, min_periods=sma_period).mean()

    # RSI
    delta = df["close"].diff()
    gain = np.where(delta > 0, delta, 0.0)
    loss = np.where(delta < 0, -delta, 0.0)
    roll_gain = pd.Series(gain, index=df.index).rolling(rsi_period, min_periods=rsi_period).mean()
    roll_loss = pd.Series(loss, index=df.index).rolling(rsi_period, min_periods=rsi_period).mean()
    rs = roll_gain / roll_loss.replace(0, np.nan)
    df["rsi"] = 100 - (100 / (1 + rs))
    df["rsi"] = df["rsi"].bfill()  # suavizar arranque

    # Se√±al estilo rsi_sma (long-only): 
    # entrada si precio > SMA y RSI < rsi_buy; salida si RSI > rsi_sell
    # (aj√∫stalo a tu l√≥gica exacta si difiere)
    df["position"] = 0
    in_pos = False
    for i in range(len(df)):
        price = df.at[i, "close"]
        sma   = df.at[i, "sma"]
        rsi   = df.at[i, "rsi"]
        if not np.isnan(sma):
            if not in_pos and price > sma and rsi <= rsi_buy:
                df.at[i, "position"] = 1
                in_pos = True
            elif in_pos and rsi >= rsi_sell:
                df.at[i, "position"] = -1
                in_pos = False
        # Si no hay se√±al nueva, mantener 0 (el bot gestiona el estado con su variable `position`)
    return df

def tail_log_last_signal(log_path: Path) -> dict | None:
    if not log_path.exists():
        return None
    tail = log_path.read_text(encoding="utf-8", errors="ignore").splitlines()[-200:]
    # Buscar la √∫ltima l√≠nea con "Precio: ... | Se√±al: ..."
    pat = re.compile(r"Precio:\s*([0-9.]+)\s*\|\s*Se√±al:\s*(-?1|0)")
    last = None
    for ln in reversed(tail):
        m = pat.search(ln)
        if m:
            price = float(m.group(1))
            sig = int(m.group(2))
            last = {"price": price, "signal": sig, "raw": ln}
            break
    return last

def pick_best_from_optimization(opt_path: Path):
    if not opt_path.exists():
        return None
    df = pd.read_csv(opt_path)
    need = {"total_return", "sharpe_ratio", "max_drawdown", "rsi_period", "sma_period", "rsi_buy", "rsi_sell"}
    if not need.issubset(df.columns):
        return None

    # Score robusto: prioriza retorno pero penaliza DD profundo y Sharpe bajo
    # normalizaci√≥n simple para ranking
    d = df.copy()
    d = d.dropna(subset=["total_return", "sharpe_ratio", "max_drawdown"])
    if d.empty:
        return None

    # Evitar divisiones por cero / escalas raras
    d["ret_z"]   = (d["total_return"] - d["total_return"].mean()) / (d["total_return"].std(ddof=0) + 1e-9)
    d["sharpe_z"] = (d["sharpe_ratio"] - d["sharpe_ratio"].mean()) / (d["sharpe_ratio"].std(ddof=0) + 1e-9)
    # drawdown es negativo; m√°s cercano a 0 es mejor ‚Üí usar el negativo
    d["dd_z"] = - (d["max_drawdown"] - d["max_drawdown"].mean()) / (d["max_drawdown"].std(ddof=0) + 1e-9)

    # Ponderaci√≥n
    d["score"] = 0.6 * d["ret_z"] + 0.3 * d["sharpe_z"] + 0.1 * d["dd_z"]
    best = d.sort_values("score", ascending=False).iloc[0]
    return {
        "params": {
            "rsi_period": int(best["rsi_period"]),
            "sma_period": int(best["sma_period"]),
            "rsi_buy": int(best["rsi_buy"]),
            "rsi_sell": int(best["rsi_sell"]),
        },
        "metrics": {
            "total_return": float(best["total_return"]),
            "sharpe_ratio": float(best["sharpe_ratio"]),
            "max_drawdown": float(best["max_drawdown"]),
            "score": float(best["score"]),
        }
    }

def main():
    print("\nüîé 1) ¬øQu√© par√°metros est√° usando AHORA el bot segun el selector?")
    strat_name, strat_fn, params, metrics = select_best_strategy(tf="15m")
    print(f"   ‚Ä¢ Estrategia : {strat_name}")
    print(f"   ‚Ä¢ Params     : {params}")
    print(f"   ‚Ä¢ M√©tricas   : {metrics}")

    print("\nüß™ 2) Validaci√≥n del CSV en memoria (sin tocar el archivo):")
    df = load_and_validate_csv(DATA_PATH)
    print(f"   ‚Ä¢ Filas v√°lidas: {len(df)}   rango: {df['timestamp'].iloc[0]} ‚Üí {df['timestamp'].iloc[-1]}")

    # Detectar gaps de 15m y timestamps no monot√≥nicos
    diffs = df["timestamp"].diff().dropna().dt.total_seconds()
    bad_gap = diffs[(diffs != 900.0) & (diffs != 0.0)]  # 900s = 15m; 0 si hay duplicado (ya limpiado)
    if not bad_gap.empty:
        print(f"   ‚Ä¢ ‚ö†Ô∏è Gaps o irregularidades detectados en {len(bad_gap)} puntos (p.ej. velas faltantes).")

    # Recalcular indicadores y se√±al con los par√°metros en uso
    df_ind = compute_indicators_and_signal(df.copy(), **params)
    last = df_ind.iloc[-1]
    print("\nüìà 3) √öltimos valores recalculados:")
    print(f"   ‚Ä¢ close: {last.close:.2f}  SMA({params['sma_period']}): {last.sma:.2f}  RSI({params['rsi_period']}): {last.rsi:.2f}")
    print(f"   ‚Ä¢ Se√±al calculada (esta vela): {int(last.position)}")

    # Comparar con lo que logue√≥ el bot
    log_last = tail_log_last_signal(LOG_PATH)
    if log_last:
        print("\nü™µ 4) √öltima se√±al seg√∫n logs:")
        print(f"   ‚Ä¢ Log: {log_last['raw']}")
        # Nota: el bot mantiene un estado de posici√≥n; si en la vela anterior se entr√≥/sali√≥,
        # puede que esta vela registre 0 aunque nuestra l√≥gica base genere 1/-1 solo en el cruce.
        # Aun as√≠, suele coincidir el *timing* de las se√±ales.
        print(f"\nüîÅ 5) Comparativa r√°pida:")
        print(f"   ‚Ä¢ Se√±al log    : {log_last['signal']}")
        print(f"   ‚Ä¢ Se√±al calc   : {int(last.position)}")
        if int(last.position) != log_last["signal"]:
            print("   ‚Ä¢ ‚ö†Ô∏è Diferencia detectada: revisa la l√≥gica exacta de tu rsi_sma en src/strategy/rsi_sma.py")
        else:
            print("   ‚Ä¢ ‚úÖ Coinciden.")
    else:
        print("\nü™µ 4) No encontr√© una l√≠nea de se√±al en logs recientes. Revisa logs/live_trader.log")

    # (Opcional) mostrar el ‚Äúmejor‚Äù set de results/rsi_optimization_15m.csv si existe
    if OPT_PATH.exists():
        best_opt = pick_best_from_optimization(OPT_PATH)
        if best_opt:
            print("\nüèÅ 6) Mejor set seg√∫n results/rsi_optimization_15m.csv (score robusto):")
            print(f"   ‚Ä¢ Params  : {best_opt['params']}")
            print(f"   ‚Ä¢ M√©tricas: {best_opt['metrics']}")
            # ¬øCoincide con los que usa el bot?
            same = all(int(params[k]) == int(best_opt["params"][k]) for k in ["rsi_period","sma_period","rsi_buy","rsi_sell"])
            print(f"   ‚Ä¢ ¬øCoinciden con los del bot?: {'‚úÖ S√≠' if same else '‚ùå No'}")
        else:
            print("\n‚ÑπÔ∏è 6) No pude interpretar results/rsi_optimization_15m.csv (faltan columnas o est√° vac√≠o).")
    else:
        print("\n‚ÑπÔ∏è 6) No hay results/rsi_optimization_15m.csv, el selector no puede apoyarse en ese hist√≥rico.")

    # Sugerencia de saneo si hubo l√≠neas malas
    print("\nüßπ Sugerencia de saneo si detectaste l√≠neas corruptas en el CSV:")
    print(f"""   ‚Ä¢ Haz un backup y reescr√≠belo limpio con:
       python - <<'PY'
import pandas as pd
df = pd.read_csv("{DATA_PATH.as_posix()}")
df["timestamp"] = pd.to_datetime(df["timestamp"], utc=True, errors="coerce")
df = df.dropna(subset=["timestamp"]).sort_values("timestamp").drop_duplicates(subset=["timestamp"], keep="last")
for col in ["open","high","low","close","volume"]: df[col] = pd.to_numeric(df[col], errors="coerce")
df = df.dropna(subset=["open","high","low","close","volume"]).reset_index(drop=True)
df.to_csv("{DATA_PATH.as_posix()}", index=False)
print("CSV saneado y reescrito")
PY
    """)

if __name__ == "__main__":
    main()
